#!/usr/bin/env python

###############################################################
####### This script will spit out png files monitoring ########
####### the copy status through Phedex on three levels: #######
####### -per replica, -per request, -per site #################
#
####### yiiyama@mit.edu, bmaier@mit.edu #######################
###############################################################

import sys
import os
import time
import shutil
import selinux
import collections
import csv

from datetime import datetime, timedelta

from argparse import ArgumentParser

parser = ArgumentParser(description = 'Track transfers')
parser.add_argument('--config', '-c', metavar = 'CONFIG', dest = 'config', required = True, help = 'Configuration JSON.')

args = parser.parse_args()
sys.argv = []

from dynamo.dataformat import Configuration
from dynamo.utils.parallel import Map
import dynamo.core.executable as executable

## Configuration

config = Configuration(args.config)

## Logger
LOG = executable.make_standard_logger(config.log_level)

## Data source
from dynamo.dataformat.history import HistoryRecord
from dynamo.dealer.history import DealerHistoryBase

from dynamo.core.executable import inventory
from dynamo.dataformat import Site

from dynamo.utils.interface.phedex import PhEDEx
from dynamo.utils.interface.mysql import MySQL

from dynamo.fileop.rlfsm import RLFSM

nowTime = int(time.time())
maxTime = nowTime - 10*360*24*60*60
futureTime = nowTime + 1*360*24*60*60

phedex = PhEDEx(config.phedex)

rlfsm = RLFSM()
#rlfsm = RLFSM(Configuration(db = {'user': 'some_user', 'passwd': 'passwd'})

class Request(object):
    __slots__ = ['reqid','target','missFiles','submitted','updateRequests','addMissFiles','addSubmitted']

    def __init__(self, reqid,target):
        self.reqid = reqid
        self.target = target
        self.missFiles = {}
        self.submitted = {}

    def updateRequest(self,target,dsetName):
        if target != self.target:
            print 'targets mismatch: ' + target + '!=' + self.target + " " + str(self.reqid)
            return

        if '#' in dsetName:
            dsetName = dsetName.split('#')[0]
        if dsetName not in self.missFiles:
            self.missFiles[dsetName] = []

    def addMissFiles(self,dsetName,fileName):
        self.missFiles[dsetName].append(fileName)

    def addSubmitted(self,dsetName,fileName):
        if dsetName not in self.submitted:
            self.submitted[dsetName] = []
        self.submitted[dsetName].append(fileName)

def looksLikeStuck(invObj, site, tdate):
    if (nowTime - tdate) < 60*60*24*14:
        return False
    if 'T0_'  in site : return False
    if 'T3_'  in site : return False
    if '_MSS' in site : return False

    if site not in inventory.sites:
        return False
    #if inventory.sites[site].status != Site.STAT_READY:
    #    return False

    return True

def findTrueMissing(invObj,dsetName,siteName,fHandle):

    statVals = ['block='+dsetName+'#*','node=' + siteName]
    status = phedex.make_request('filereplicas', statVals)
    phedRepFiles = set()
    for block in status:
        for allFiles in block['file']:
            phedRepFiles.add(allFiles['name'])
    l1 = len(phedRepFiles)

    dsetObj = inventory.datasets[dsetName]
    dynamoAllFiles = set()
    for blockObj in dsetObj.blocks:
        for fileObj in blockObj.files:
            dynamoAllFiles.add(fileObj.lfn)
    l2 = len(dynamoAllFiles)

    missing = dynamoAllFiles.symmetric_difference(phedRepFiles)
    if len(missing) != (l2 - l1):
        fHandle.write(siteName + " " + str(l2 - l1) + " != " + str(len(missing)) + dsetName)
        fHandle.write("\n")
    return missing

def belongsToAnaOps(dsetRep,invObj):
    anaOps = True
    doprint = False

    for blockRep in dsetRep.block_replicas:
        if doprint:
            print blockRep.block.name
            print blockRep.group.name
            print blockRep._group_name()
            print blockRep.size
        if not (blockRep.size > 0):
            continue
        if blockRep.group is None:
            continue
        if blockRep.group.name == 'None':
            continue
        if blockRep.group != invObj.groups['AnalysisOps']:
            anaOps = False
    return anaOps

def belongsToDataOps(dsetRep,invObj):
    dataOps = False

    for blockRep in dsetRep.block_replicas:
        if not (blockRep.size > 0):
            continue
        if blockRep.group is None:
            continue
        if blockRep.group.name == 'None':
            continue
        if blockRep.group == invObj.groups['DataOps']:
            dataOps = True
            break
    return dataOps

def shouldBeDeleted(dsetObj,siteName,invObj):
    fullOnTape = False
    fullOnDisk = False
    anaOpsTarg = True
    anaOpsOtro = True
    for theRep in dsetObj.replicas:
        if siteName == theRep.site.name:
            anaOpsTarg = belongsToAnaOps(theRep,invObj)

        if theRep.is_full():
            if '_MSS' in theRep.site.name:
                fullOnTape = True
            else:
                fullOnDisk = True
                anaOpsOtro = belongsToAnaOps(theRep,invObj)
                if siteName == theRep.site.name:
                    return False
    
#    print str(fullOnTape) + " " + str(fullOnDisk) + " " + str(anaOpsOtro) + " " + str(anaOpsTarg)
    return (fullOnTape & fullOnDisk & anaOpsOtro & anaOpsTarg)


def isPhantasma(dsetObj,siteName,missFiles,invObj):
    homeAlone = True
    zeroAtDest = False
    isOnTape = False
    anaOpsTarg = False

    if 'Run2018' in dsetObj.name:
        return False
    if 'RAW' in dsetObj.name:
        return False

    for theRep in dsetObj.replicas:
        if siteName == theRep.site.name:
            anaOpsTarg = belongsToAnaOps(theRep,invObj)

            filesInDset = 0
            for block in dsetObj.blocks:
                try:
                    filesInDset += len(block.files)
                except:
                    return False
            if float(missFiles)/float(filesInDset) > 0.15 :
                zeroAtDest = True
        else:
            if '_MSS' in siteName:
                isOnTape = True
            homeAlone = False

 #   print str(zeroAtDest) + " " + str(homeAlone) + " " + str(anaOpsTarg)
    return (zeroAtDest & homeAlone & anaOpsTarg)

def deleteDataset(siteName,dsetObj):
    full_catalog = {}
    full_catalog[dsetObj] = []
    options = {
        'node': siteName,
        'data': phedex.form_catalog_xml(full_catalog),
        'level': 'dataset',
        'rm_subscriptions': 'y'}
    
    try:
        result = phedex.make_request('delete', options, method = POST)
    except:
        print " failed the deletion attempt"
        print siteName + " " + dsetObj.name
        return

    reqid = int(result[0]['id']) # return value is a string
    print "!!!!!!!!!!! deletion reqid = " + str(reqid) + " " + siteName + " " + dsetObj.name
    result = phedex.make_request('updaterequest', 
                                 {'decision': 'approve', 'request': reqid, 'node': siteName}, method = POST)

def update_progress(job_title, progress):
    length = 35 # modify this to change the length
    block = int(round(length*progress))
    msg = "\r{0}: [{1}] {2}%".format(job_title, "#"*block + "-"*(length-block), round(progress*100, 2))
    if progress >= 1: msg += " DONE\r\n"
    sys.stdout.write(msg)
    #sys.stdout.flush()

inventory = executable.inventory

phedexStuck = {}
dynamoStuck = {}
doneRequests = {}

print " ... starting execution"

GET, POST = range(2)
datasets = phedex.make_request('subscriptions', ['percent_max=99.999','move=n','create_since=%d' % maxTime])
print " ... got phedex call"
fsusp = open('/tmp/suspended.txt','w')
for dataset_entry in datasets:
    if 'block' in dataset_entry:
        for block_entry in dataset_entry['block']:
            for subscription in block_entry['subscription']:
                reqid = int(subscription["request"])
                site =  subscription["node"]
                tdate =  int(subscription['time_update'])
                dsetName = block_entry['name']

                if dsetName.startswith('/GenericTTbar/'):
                    continue

                if subscription['suspended'] == 'y':
                    if site.startswith('T3_'):
                        continue
                    sustime = int(subscription['suspend_until'])
                    if sustime < futureTime:
                        continue
                    else:
                        fsusp.write(site + " " + str(reqid) + " " + dsetName + "\n")
                
                if not looksLikeStuck(inventory, site, tdate):
                    continue

                if reqid not in phedexStuck:
                    phedexStuck[reqid] = Request(reqid,site)
                phedexStuck[reqid].updateRequest(site,dsetName)
    else:
        for subscription in dataset_entry['subscription']:
            reqid = subscription["request"]
            site =  subscription["node"]
            tdate = int(subscription['time_update'])
            dsetName = dataset_entry['name']
            sustime = subscription['suspend_until']

            if dsetName.startswith('/GenericTTbar/'):
                continue

            if subscription['suspended'] == 'y':
                if site.startswith('T3_'):
                    continue
                sustime = int(subscription['suspend_until'])
                if sustime < futureTime:
                    continue
                else:
                    fsusp.write(site + " " + str(reqid) + " " + dsetName + "\n")
            
            if not looksLikeStuck(inventory, site, tdate):
                continue
            
            if reqid not in phedexStuck:
                phedexStuck[reqid] = Request(reqid,site)
            phedexStuck[reqid].updateRequest(site,dsetName)

fsusp.close()
print " Number of PhEDEx stuck requests = " + str(len(phedexStuck.keys()))
sys.stdout.flush()

processed = 0
totalLength = len(phedexStuck)
for reqid in sorted(phedexStuck):
    target = phedexStuck[reqid].target
    datasets = phedexStuck[reqid].missFiles.keys()

    for dsetName in datasets:
        statVals = ['block='+dsetName+'#*','node=' + target]
        status = phedex.make_request('missingfiles', statVals)
        for block in status:
            for allFiles in block['file']:
                phedexStuck[reqid].addMissFiles(dsetName,allFiles['name'])
    processed += 1
    update_progress("Missing Files", processed/float(totalLength))

for reqid in sorted(phedexStuck.keys()):
    stuckReq = phedexStuck[reqid]
    for dset in stuckReq.missFiles.keys():
        if len(stuckReq.missFiles[dset]) < 1:
            del stuckReq.missFiles[dset]
    if len(stuckReq.missFiles) < 1:
        del phedexStuck[reqid]

print " ... completed call for missing files"
    
set2 = set(phedexStuck.keys())

submitted = {}
if os.path.isfile("/tmp/submitted.txt"):
    subFileIn = open('/tmp/submitted.txt','r')
    lineArray = []
    for line in subFileIn:
        line = line.strip()
        if line == '':
            reqid = int(lineArray[0])
            target = lineArray[1]
            dsetName = lineArray[2]
            restLines = lineArray[3:]
            submitted[(reqid,target,dsetName)] = restLines
            del lineArray[:]
        else:
            lineArray.append(line)

    subFileIn.close()


#now for all submitted requests we check how many are already done 
for (reqid,target,dsetName) in submitted.keys():
    siteObj = inventory.sites[target]
    dsetObj = inventory.datasets[dsetName]
    dataset_replica = siteObj.find_dataset_replica(dsetObj)

    if dataset_replica is None:
        print str(reqid) + " " + target + " " + dsetName
        print " -- replica does not exist in inventory"
        continue

    if dataset_replica.is_complete():
        #time to update phedex
        print "\n" + str(reqid) + " " + target+ " " + dsetName
        if reqid not in phedexStuck:
            print " -- all is done by magic"
            del submitted[reqid,target,dsetName]
        else:
            #update PhEDEx here
            values = ['dataset=' + dsetName,'node=' + target,'suspend_until=%d' % int(time.time() + 3600*3)]
            try:
                phedex.make_request('updatesubscription',values,method=POST)
                print '!!!!!!! Sucess !!!!!!!!'
                del submitted[reqid,target,dsetName]
            except:
                print(" -- can't resubmit that request:", sys.exc_info()[0])
    else:
        if reqid not in phedexStuck:
            print "\n" + str(reqid) + " " + target + " " + dsetName
            print "WOWOWOW = need to wait for delta update"

nfis = open('/tmp/uncompleted.txt','w')
miss = open('/tmp/missingSets.txt','w')

totalTransfers = 0
totalVolume = 0
totalReqs = 0
totDeleted = 0

#for reqid in sorted(matched):
for reqid in sorted(set2):
    reqObj = phedexStuck[reqid]
    target = reqObj.target
    reqid  = reqObj.reqid
    datasets = reqObj.missFiles.keys()
    siteObj = inventory.sites[target]

    for dsetName in datasets:
        if (reqid,target,dsetName) in submitted:
            print "already submitted, skipping"
            continue

        if dsetName not in inventory.datasets:
            print " .. not found " + dsetName
            miss.write(siteObj.name + " " + dsetName + "\n")
            continue
                
        dsetObj = inventory.datasets[dsetName]
        dataset_replica = siteObj.find_dataset_replica(dsetObj)
        if dataset_replica is None:
            miss.write(siteObj.name + " " + dsetName + "\n")
            continue

        missFiles = reqObj.missFiles[dsetName]
        filesInDset = 0
        for block in dsetObj.blocks:
            try:
                filesInDset += len(block.files)
            except:
                continue

        if inventory.sites[target].status != Site.STAT_READY:
            print " ------>> reqid = " + str(reqid) + " " + target + " is to bad site"
            print dsetObj.name
            anaOpsTarget = belongsToAnaOps(dataset_replica,inventory)
            if (anaOpsTarget) and (totDeleted < 20):
                print " will delete it"
                deleteDataset(target,dsetObj)
                totDeleted += 1
            continue


        tobegone = isPhantasma(dsetObj,target,len(missFiles),inventory)
        if tobegone and (totDeleted < 20):
            print " --- " + str(reqid) + " " + target + " " + str(len(missFiles)) + " " + dsetName
            print " --- missing " + str(len(missFiles)) + " out of " + str(filesInDset)
            for theRep in dsetObj.replicas:
                print " .. also found at " + theRep.site.name + " " + str(theRep.is_complete()) + " " + str(theRep.is_full())

            deleteDataset(target,dsetObj)
            totDeleted += 1
            continue

        if len(missFiles) > 500:
            print " --- " + str(reqid) + " " + target + " " + str(len(missFiles)) + " " + dsetName
            print " --- missing " + str(len(missFiles)) + " out of " + str(filesInDset)
            for theRep in dsetObj.replicas:
                print " .. also found at " + theRep.site.name + " " + str(theRep.is_complete()) + " " + str(theRep.is_full())

            dodelete = shouldBeDeleted(dsetObj,target,inventory)
            if dodelete and (totDeleted < 20):
                deleteDataset(target,dsetObj)
                totDeleted += 1
            
            continue

        for fileName in missFiles:
            fileObj = None
            try:
                fileObj =  dsetObj.find_file(fileName)
            except:
                pass
                
            if fileObj is None:
                #print " .. problem with objects " + dsetName
                #print fileName
                continue
            blockObj = fileObj.block

            block_replicas = blockObj.replicas
        
            sources = []
            for blockRepObj in block_replicas:
                if not blockRepObj.is_complete:      continue
                if blockRepObj.site.name == target:  continue
                if blockRepObj.site.status != Site.STAT_READY: continue
                sources.append(blockRepObj.site.name)
                
            if len(sources) == 0:
                #nfis.write(str(dsetObj.size/(1000000000000)) + " TBs  " + dsetName + '\n')
                nfis.write("{0:6.2f} TBs  {1:s} \n".format(dsetObj.size/(1000000000000), dsetName) )
                break

            sources = [x for x in sources if "Export" not in x]
            sources = [x for x in sources if "Buffer" not in x]
            nontape = [x for x in sources if "MSS" not in x]
            if len(nontape) > 0:  sources = nontape                
            if len(sources) == 0: continue

            rlfsm.subscribe_file(siteObj, fileObj)

            totalTransfers += 1
            totalVolume += fileObj.size
            reqObj.addSubmitted(dsetName,fileName)
            
    totalReqs += 1
    if len(reqObj.submitted.keys()) > 0:
        print target + " " + str(reqid) + " : " + str(len(reqObj.submitted.keys())) ,
        print [len(v) for v in reqObj.submitted.values()]
                 
        for dsetName in reqObj.submitted:
            submitted[(reqid,target,dsetName)] = [str(nowTime)]

            for fileName in reqObj.submitted[dsetName]:
                submitted[(reqid,target,dsetName)].append(fileName)

nfis.close()
miss.close()

subFileOut = open('/tmp/submitted.txt','w')
for (reqid,target,dsetName) in sorted(submitted, key = lambda x: (int(submitted[x][0]),x[0]) ):
    subFileOut.write(str(reqid) + '\n')
    subFileOut.write(target + '\n')
    subFileOut.write(dsetName + '\n')
    for line in submitted[(reqid,target,dsetName)]:
        subFileOut.write(line + '\n')
    subFileOut.write('\n')

subFileOut.close()

print " Tot Trans = " + str(totalTransfers) + ", Volume = ",
print str(int(totalVolume/(1024*1024*1024*1024))) + " TBs"
                


   



